name: Bake CSV into HTML (bash only)

on:
  push:
    paths:
      - data/oris_data.csv
      - docs/index.tmpl.html
      - .github/workflows/bake-data-into-html.yml
  workflow_dispatch:

jobs:
  bake:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Sanity check files
        shell: bash
        run: |
          set -euo pipefail
          ls -la
          ls -la docs || true
          ls -la data || true
          test -f docs/index.tmpl.html || { echo "ERROR: docs/index.tmpl.html not found"; exit 1; }
          test -f data/oris_data.csv   || { echo "ERROR: data/oris_data.csv not found"; exit 1; }
          if grep -q "__ORIS_DATA__" docs/index.tmpl.html; then
            echo "Found __ORIS_DATA__ token in template."
          elif grep -q "<!--DATA:START-->" docs/index.tmpl.html; then
            echo "Found DATA markers."
          else
            echo "WARNING: No placeholder found in template."
          fi

      - name: Convert CSV -> JSON (gawk, mapped fields; here-doc to avoid quoting issues)
        shell: bash
        run: |
          set -euo pipefail
          CSV="data/oris_data.csv"
          JSON="data/oris_data.json"

          # Write the awk program to a temp file so we don't fight YAML/quote escaping.
          cat > /tmp/csv2json.awk <<'AWK'
          BEGIN {
            OFS = ""
            # Parse CSV correctly: fields are either unquoted chunks without commas,
            # or quoted strings that can contain commas and doubled quotes.
            FPAT = "([^,]+)|(\"([^\"]|\"\")*\")"
            print "["
            row = 0
          }

          # Utility: JSON-escape a string
          function json_escape(s) {
            gsub(/\\/, "\\\\", s)
            gsub(/\"/, "\\\"", s)
            gsub(/\r/, "", s)
            return s
          }

          # Utility: read field i, strip outer quotes and un-double inner quotes
          function field(i,  v) {
            if (i <= 0 || i > NF) return ""
            v = $(i)
            gsub(/^"|"$/, "", v)
            gsub(/""/, "\"", v)
            return v
          }

          # Header row: map column names (support common fallbacks)
          NR == 1 {
            for (i = 1; i <= NF; i++) {
              h = $(i)
              gsub(/^"|"$/, "", h)
              idx[h] = i
            }

            d_i   = ("datum"       in idx) ? idx["datum"]       : (("date" in idx) ? idx["date"] : (("Date" in idx) ? idx["Date"] : 0))
            name_i= ("zavod_nazev" in idx) ? idx["zavod_nazev"] : (("nazev" in idx) ? idx["nazev"] : (("name" in idx) ? idx["name"] : 0))
            place_i=("misto_konani"in idx) ? idx["misto_konani"]: (("misto" in idx) ? idx["misto"] : (("place" in idx) ? idx["place"] : 0))
            link_i= ("url"         in idx) ? idx["url"]         : (("link" in idx) ? idx["link"] : 0)
            gps_i = ("gps_zavod"   in idx) ? idx["gps_zavod"]   : (("gps"  in idx) ? idx["gps"]  : 0)

            if (!d_i || !gps_i) {
              printf "Missing required columns (datum/date or gps_zavod/gps)\n" > "/dev/stderr"
              exit 1
            }
            next
          }

          # Data rows
          {
            if (NF == 0) next

            date  = field(d_i)
            name  = field(name_i)
            place = field(place_i)
            link  = field(link_i)
            gps   = field(gps_i)

            if (gps == "") next

            # Split "lat,lon" (allowing optional spaces)
            nsplit = split(gps, parts, /, */)
            if (nsplit < 2) next
            lat = parts[1]; lon = parts[2]
            gsub(/^ +| +$/, "", lat)
            gsub(/^ +| +$/, "", lon)

            # Validate numeric coords
            if (lat !~ /^-?[0-9]+(\.[0-9]+)?$/) next
            if (lon !~ /^-?[0-9]+(\.[0-9]+)?$/) next

            if (row++ > 0) printf ",\n"
            printf "{"
            printf "\"date\":\"%s\"",  json_escape(date)
            printf ",\"name\":\"%s\"",  json_escape(name)
            printf ",\"place\":\"%s\"", json_escape(place)
            printf ",\"link\":\"%s\"",  json_escape(link)
            printf ",\"lat\":%s",       lat+0
            printf ",\"lon\":%s",       lon+0
            printf "}"
          }

          END {
            print "\n]"
          }
          AWK

          # Run with gawk (more forgiving than mawk for FPAT etc.)
          gawk -f /tmp/csv2json.awk "$CSV" > "$JSON"

          echo "Wrote $(wc -c < "$JSON") bytes to $JSON"
          echo "Preview of JSON:"
          head -c 500 "$JSON" || true
          echo
          
      - name: Inject JSON into template
        shell: bash
        run: |
          set -euo pipefail
          TEMPLATE="docs/index.tmpl.html"
          OUT="docs/index.html"
          JSON="data/oris_data.json"

          if grep -q '<!--DATA:START-->' "$TEMPLATE"; then
            echo "Using marker replacement."
            TMP_SNIP="$(mktemp)"
            {
              echo '<script>'
              echo -n '  window.ORIS_DATA = '
              cat "$JSON"
              echo ';'
              echo '</script>'
            } > "$TMP_SNIP"

            awk -v snip="$TMP_SNIP" '
              BEGIN{ while((getline l<snip)>0){ repl=repl l "\n" } }
              {
                if (state==0) {
                  if ($0 ~ /<!--DATA:START-->/) { print "<!--DATA:START-->"; printf "%s", repl; state=1 }
                  else print
                } else {
                  if ($0 ~ /<!--DATA:END-->/) { print "<!--DATA:END-->"; state=0 }
                }
              }
              END{ if (state==1) print "<!--DATA:END-->" }
            ' "$TEMPLATE" > "$OUT"
            rm -f "$TMP_SNIP"
          else
            echo "Using __ORIS_DATA__ token replacement."
            sed -e "/__ORIS_DATA__/{
              r $JSON
              s/__ORIS_DATA__//g
            }" "$TEMPLATE" > "$OUT"
          fi

          echo "Built $OUT"
          nl -ba "$OUT" | sed -n '1,40p'

      - name: Upload built HTML (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: built-index-html
          path: docs/index.html

      - name: Commit & push if changed (supports new file)
        shell: bash
        run: |
          set -euo pipefail
          git add -N docs/index.html || true   # include untracked in diff
          if git diff --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git add docs/index.html data/oris_data.json
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git commit -m "Bake data into docs/index.html"
          git push
