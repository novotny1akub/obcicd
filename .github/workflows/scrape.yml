name: Scrape ORIS daily

on:
  schedule:
    - cron: "10 4 * * *"    # 04:10 UTC
  workflow_dispatch: {}

permissions:
  contents: write            # allow pushing commits

jobs:
  run-r:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    container:
      image: rocker/r2u:24.04

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Install tools and CRAN binaries
        run: |
          apt-get update
          apt-get install -y git ca-certificates
          apt-get install -y \
            r-cran-tidyverse r-cran-rvest r-cran-xml2 \
            r-cran-stringr r-cran-purrr r-cran-readr

      - name: Run scraper
        run: Rscript scrape_oris.R

      # 🔒 Commit only if there are changes; avoids “not a git repo” issues
      - name: Commit & push new data (if changed)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Only add if files exist (first runs may not create anything)
          if ls data/*.csv >/dev/null 2>&1; then
            git add data/*.csv
          fi

          # Commit only when there are staged changes
          if ! git diff --cached --quiet; then
            git commit -m "chore: update ORIS scrape ($(date +'%Y-%m-%d'))"
            git push
          else
            echo "No data changes to commit."
          fi

      # Optional: keep a downloadable artifact of the CSV(s)
      - name: Upload artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: oris-scrape-${{ github.run_id }}
          path: data/*.csv
          if-no-files-found: ignore
